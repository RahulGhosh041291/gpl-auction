# CricHeroes Integration Implementation

## Overview

The `fetch_cricheroes_data()` function in `backend/routers/registration.py` now has a working implementation that fetches player statistics from CricHeroes profiles using web scraping.

## How It Works

### Input Formats Accepted

The function accepts CricHeroes profile information in three formats:

1. **Full URL** (Recommended)
   ```
   https://cricheroes.in/player-profile/123456/player-name
   ```

2. **Profile Path** (ID + Name)
   ```
   123456/player-name
   ```

3. **Profile ID Only** (May not work reliably)
   ```
   123456
   ```

### What Data Is Fetched

The function extracts the following statistics from CricHeroes profiles:

- **Matches Played** - Total number of matches
- **Runs Scored** - Total runs in career
- **Wickets Taken** - Total wickets in career
- **Batting Average** - Career batting average
- **Bowling Average** - Career bowling average
- **Strike Rate** - Batting strike rate
- **Batting Style** - e.g., "Right-hand bat", "Left-hand bat"
- **Bowling Style** - e.g., "Right-arm fast", "Left-arm spin"

### Technology Stack

- **requests** - HTTP client for fetching web pages
- **BeautifulSoup4** - HTML parsing and data extraction
- **lxml** - Fast XML/HTML parser (BeautifulSoup backend)
- **Regular Expressions** - Pattern matching for statistics

## Implementation Details

### Web Scraping Approach

The function:
1. Accepts a CricHeroes profile identifier (URL, path, or ID)
2. Constructs the full profile URL
3. Sends an HTTP request with browser-like headers to avoid blocking
4. Parses the HTML response using BeautifulSoup
5. Searches for statistics using CSS selectors and regex patterns
6. Extracts numerical data and playing styles
7. Returns a dictionary with player stats or `None` on failure

### Error Handling

The implementation handles multiple error scenarios:

- **Network Errors** - Connection timeouts, DNS failures
- **HTTP Errors** - 404 Not Found, 500 Server Error
- **Parsing Errors** - Invalid HTML structure
- **Missing Data** - Profiles with incomplete statistics
- **Private Profiles** - Restricted access

### Graceful Degradation

- If web scraping packages aren't installed, the function returns `None`
- If data extraction fails, returns `None` without crashing
- Logs detailed error messages for debugging
- Registration process continues even if CricHeroes fetch fails

## Testing

### Test Script

A test script is provided at `backend/test_cricheroes.py`:

```bash
# Test with a profile URL
python test_cricheroes.py https://cricheroes.in/player-profile/123456/player-name

# Test with profile path
python test_cricheroes.py 123456/player-name
```

### Manual Testing via API

You can test the integration through the FastAPI endpoint:

1. Start the backend server:
   ```bash
   cd backend
   uvicorn main:app --reload
   ```

2. Visit the API docs: `http://localhost:8000/docs`

3. Test the `/api/registration/check-cricheroes/{cricheroes_id}` endpoint

4. Try with different profile formats:
   - Full URL: `https://cricheroes.in/player-profile/123456/player-name`
   - Profile path: `123456/player-name`
   - Just ID: `123456`

## Usage in Registration Flow

### How It's Integrated

When a player registers through the frontend:

1. Player fills out the registration form
2. Player optionally provides their CricHeroes profile URL/ID
3. Backend receives the registration data
4. If `cricheroes_id` is provided:
   - `fetch_cricheroes_data()` is called
   - Player stats are fetched from CricHeroes
   - Stats are stored in the database
   - `has_cricheroes_data` flag is set to `True`
5. If fetch fails or no ID provided:
   - Registration continues normally
   - Stats remain at default values (0)
   - `has_cricheroes_data` is `False`

### Database Fields Updated

When CricHeroes data is successfully fetched:

```python
player.has_cricheroes_data = True
player.matches_played = cricheroes_data.get("matches_played", 0)
player.runs_scored = cricheroes_data.get("runs_scored", 0)
player.wickets_taken = cricheroes_data.get("wickets_taken", 0)
player.batting_average = cricheroes_data.get("batting_average", 0.0)
player.bowling_average = cricheroes_data.get("bowling_average", 0.0)
player.strike_rate = cricheroes_data.get("strike_rate", 0.0)
player.batting_style = cricheroes_data.get("batting_style")  # If not provided
player.bowling_style = cricheroes_data.get("bowling_style")  # If not provided
```

## Important Notes

### ‚ö†Ô∏è Limitations

1. **Web Scraping Fragility**
   - CricHeroes may change their HTML structure, breaking the scraper
   - Requires periodic maintenance to adapt to site changes
   
2. **Rate Limiting**
   - Too many requests may trigger IP blocking
   - Consider implementing request throttling for production
   
3. **Profile Access**
   - Some profiles may be private or restricted
   - No data available for profiles without matches
   
4. **Data Accuracy**
   - Extracted data depends on what's publicly visible
   - May not capture all statistics depending on profile privacy settings

### üîí Privacy & Ethics

- Only fetches publicly available data
- Uses standard HTTP requests (no authentication bypass)
- Respects HTTP response codes and errors
- Implements reasonable request timeouts

### üìà Production Considerations

For production deployment:

1. **Caching** - Cache CricHeroes data to reduce requests
   ```python
   # Store fetched data with timestamp
   # Refresh only if data is older than X days
   ```

2. **Background Jobs** - Fetch data asynchronously
   ```python
   # Queue fetch jobs using Celery or similar
   # Don't block registration on data fetch
   ```

3. **Retry Logic** - Implement exponential backoff
   ```python
   # Retry failed fetches with increasing delays
   ```

4. **Monitoring** - Track success/failure rates
   ```python
   # Log metrics for debugging and optimization
   ```

## Troubleshooting

### "Module not found" errors

Install dependencies:
```bash
cd backend
pip install requests beautifulsoup4 lxml
```

Or install from requirements.txt:
```bash
pip install -r requirements.txt
```

### "Could not extract player statistics"

Possible causes:
- Invalid profile URL/ID
- Profile is private
- CricHeroes website structure changed
- Network connectivity issues

Solutions:
1. Verify the profile URL is correct and accessible
2. Check if the profile loads in a browser
3. Review server logs for detailed error messages
4. Update HTML selectors if site structure changed

### "Network timeout" errors

Solutions:
1. Check internet connectivity
2. Increase timeout value in the code
3. Check if CricHeroes is accessible from server

### Data looks incorrect

1. Verify profile URL is for the correct player
2. Check if CricHeroes updated their display format
3. Review parsing logic for the specific statistic
4. Add debug logging to see what's being extracted

## Future Enhancements

Possible improvements:

1. **Official API Integration**
   - If CricHeroes releases an official API, migrate to it
   - More reliable than web scraping

2. **Enhanced Data Extraction**
   - Extract more detailed statistics
   - Match-by-match performance history
   - Tournament-specific stats

3. **Image Extraction**
   - Fetch player profile pictures
   - Store in cloud storage (S3, Cloudinary)

4. **Performance Optimization**
   - Use async HTTP client (httpx)
   - Implement connection pooling
   - Add Redis caching layer

5. **Data Validation**
   - Sanity checks on extracted values
   - Flag suspicious data for manual review
   - Track data quality metrics

## Sample Code Reference

The implementation is based on web scraping best practices, not the sample code you provided (which doesn't match the actual `cricheroes==1.0.10` package API).

The sample code referenced a different API structure:
```python
from cricheroes import CricHeroes
client = CricHeroes()
player = client.get_player(profile_id)
```

However, the actual `cricheroes==1.0.10` package:
- Is a Selenium-based web scraper for team data
- Doesn't have a `CricHeroes()` class or `get_player()` method
- Is designed for team statistics, not individual players

Our implementation uses direct HTTP requests and BeautifulSoup, which is:
- Faster (no browser overhead)
- More lightweight (no Selenium dependencies)
- More maintainable for player profile scraping

## Support

For issues or questions:
1. Check server logs for detailed error messages
2. Test with the provided test script
3. Verify dependencies are installed
4. Review the implementation in `routers/registration.py`
